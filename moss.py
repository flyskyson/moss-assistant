"""
MOSS Assistant - ä¸»ç¨‹åº
è‹æ ¼æ‹‰åº•å¼è¾©è®ºä¼™ä¼´ + å…¨èƒ½ä¸ªäººåŠ©ç†
"""

import os
import yaml
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional

try:
    import anthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False
    print("âš ï¸  è­¦å‘Š: æœªå®‰è£… anthropic åº“ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")

from core.memory import PersistentMemory
from core.user_model import UserModelManager
from core.router import RoleRouter


class MOSSAssistant:
    """MOSS åŠ©æ‰‹æ ¸å¿ƒç±»"""

    def __init__(self, config_path: str = "config.yaml"):
        # åŠ è½½é…ç½®
        self.config = self._load_config(config_path)

        # åˆå§‹åŒ–ç»„ä»¶
        self.memory = PersistentMemory(self.config)
        self.user_model_manager = UserModelManager(self.memory)
        self.router = RoleRouter(self.config)

        # åˆå§‹åŒ– LLM
        self.llm_client = self._init_llm()

        # å½“å‰ä¼šè¯
        self.current_conversation = {
            "id": self._generate_conversation_id(),
            "timestamp": datetime.now().isoformat(),
            "messages": []
        }

    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        config_file = Path(config_path)
        if not config_file.exists():
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")

        with open(config_file, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)

    def _init_llm(self):
        """åˆå§‹åŒ– LLM å®¢æˆ·ç«¯"""
        if not ANTHROPIC_AVAILABLE:
            return None

        provider = self.config["llm"]["provider"]
        api_key = os.getenv(self.config["llm"]["api_key_env"])

        if not api_key:
            print("âš ï¸  è­¦å‘Š: æœªè®¾ç½® API Keyï¼Œè¯·è®¾ç½®ç¯å¢ƒå˜é‡")
            return None

        if provider == "claude":
            return anthropic.Anthropic(api_key=api_key)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ LLM æä¾›å•†: {provider}")

    def _generate_conversation_id(self) -> str:
        """ç”Ÿæˆå¯¹è¯ ID"""
        return f"conv_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

    def start_conversation(self) -> str:
        """å¼€å§‹å¯¹è¯ï¼ˆå†·å¯åŠ¨ï¼‰"""
        # è·å–ç”¨æˆ·æ¨¡å‹æ‘˜è¦
        summary = self.user_model_manager.get_summary()

        # æ·»åŠ åˆ°æ¶ˆæ¯å†å²
        self.current_conversation["messages"].append({
            "role": "assistant",
            "content": summary
        })

        return summary

    def chat(self, user_input: str) -> str:
        """å¤„ç†ç”¨æˆ·è¾“å…¥"""
        # æ­¥éª¤ 1: è·¯ç”±åˆ°åˆé€‚çš„è§’è‰²
        user_model = self.user_model_manager.get_model()
        routing_result = self.router.route(user_input, user_model)

        role = routing_result["role"]
        role_config = routing_result["role_config"]
        reasoning = routing_result["reasoning"]

        print(f"\nğŸ­ è§’è‰²è·¯ç”±: {role_config['name']} ({reasoning})")

        # æ­¥éª¤ 2: æ„å»ºå¯¹è¯ä¸Šä¸‹æ–‡
        messages = self._build_messages(user_input, role)

        # æ­¥éª¤ 3: è°ƒç”¨ LLM
        response = self._call_llm(messages, role)

        # æ­¥éª¤ 4: è®°å½•äº¤äº’
        self._log_interaction(user_input, response, role)

        # æ­¥éª¤ 5: æ›´æ–°ç”¨æˆ·æ¨¡å‹
        interaction = {
            "user_input": user_input,
            "agent_response": response,
            "role": role,
            "timestamp": datetime.now().isoformat()
        }
        self.user_model_manager.update_after_interaction(interaction)

        return response

    def _build_messages(self, user_input: str, role: str) -> list:
        """æ„å»ºæ¶ˆæ¯åˆ—è¡¨"""
        # è·å–è§’è‰²çš„ system prompt
        system_prompt = self.router.get_role_prompt(role)

        # è·å–ç”¨æˆ·æ¨¡å‹ä¸Šä¸‹æ–‡
        user_model = self.user_model_manager.get_model()
        user_context = self._build_user_context(user_model)

        # æ„å»ºå®Œæ•´æ¶ˆæ¯
        messages = [
            {
                "role": "user",
                "content": f"""ä½ æ˜¯{role}è§’è‰²ã€‚

{system_prompt}

ç”¨æˆ·ä¿¡æ¯ï¼š
{user_context}

ç”¨æˆ·è¾“å…¥ï¼š
{user_input}

è¯·æ ¹æ®ä½ çš„è§’è‰²å®šä½ï¼Œå›åº”ç”¨æˆ·ã€‚"""
            }
        ]

        return messages

    def _build_user_context(self, user_model: Dict[str, Any]) -> str:
        """æ„å»ºç”¨æˆ·ä¸Šä¸‹æ–‡ï¼ˆç»™ LLMï¼‰"""
        context_parts = []

        # åŸºæœ¬ä¿¡æ¯
        basic_info = user_model.get("basic_info", {})
        if any(basic_info.values()):
            context_parts.append("åŸºæœ¬ä¿¡æ¯:")
            for key, value in basic_info.items():
                if value:
                    context_parts.append(f"  - {key}: {value}")

        # è®¤çŸ¥é£æ ¼
        cognitive = user_model.get("cognitive_style", {})
        if any(cognitive.values()):
            context_parts.append("\nè®¤çŸ¥é£æ ¼:")
            for key, values in cognitive.items():
                if values:
                    context_parts.append(f"  - {key}: {', '.join(values)}")

        # æœ€è¿‘è¯é¢˜
        recent_convs = self.memory.load_conversations(limit=3)
        if recent_convs:
            context_parts.append("\næœ€è¿‘è®¨è®ºçš„è¯é¢˜:")
            for i, conv in enumerate(recent_convs, 1):
                if conv.get("messages"):
                    first_msg = conv["messages"][0].get("content", "")[:100]
                    context_parts.append(f"  {i}. {first_msg}...")

        # å½“å‰ç›®æ ‡
        goals = user_model.get("goals", {})
        if any(goals.values()):
            context_parts.append("\nå½“å‰ç›®æ ‡:")
            for timeframe, goal_list in goals.items():
                if goal_list:
                    context_parts.append(f"  - {timeframe}: {', '.join(goal_list[:2])}")

        return "\n".join(context_parts)

    def _call_llm(self, messages: list, role: str) -> str:
        """è°ƒç”¨ LLM"""
        if not ANTHROPIC_AVAILABLE or not self.llm_client:
            return self._mock_response(role)

        try:
            # ä½¿ç”¨ Claude API
            model = self.config["llm"]["model"]
            max_tokens = self.config["llm"]["max_tokens"]

            response = self.llm_client.messages.create(
                model=model,
                max_tokens=max_tokens,
                messages=messages
            )

            return response.content[0].text
        except Exception as e:
            print(f"âš ï¸  LLM è°ƒç”¨å¤±è´¥: {e}")
            return self._mock_response(role)

    def _mock_response(self, role: str) -> str:
        """æ¨¡æ‹Ÿå“åº”ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
        mock_responses = {
            "mentor": "ä½œä¸ºä½ çš„å¯¼å¸ˆï¼Œæˆ‘æƒ³å…ˆé—®ä½ å‡ ä¸ªé—®é¢˜ï¼š\n\n1. ä½ ä¸ºä»€ä¹ˆè¿™ä¸ªé€‰æ‹©å¯¹ä½ é‡è¦ï¼Ÿ\n2. ä½ æœ‰æ²¡æœ‰è€ƒè™‘è¿‡æœ€åçš„æƒ…å†µï¼Ÿ\n3. å¦‚æœ10å¹´åå›çœ‹è¿™ä¸ªå†³å®šï¼Œä½ ä¼šæœ‰ä»€ä¹ˆæ„Ÿè§‰ï¼Ÿ\n\næˆ‘ä»¬å…ˆæŠŠè¿™äº›æƒ³æ¸…æ¥šï¼Œå†åšå†³å®šã€‚",
            "partner": "è¿™ä¸ªé—®é¢˜å¾ˆæœ‰æ„æ€ï¼è®©æˆ‘ä»¬ä¸€èµ·æ¢ç´¢ä¸€ä¸‹ã€‚\n\næˆ‘æ³¨æ„åˆ°ä½ æåˆ°äº†XXï¼Œè¿™è®©æˆ‘æƒ³åˆ°å¦ä¸€ä¸ªè§’åº¦...ä½ è§‰å¾—å‘¢ï¼Ÿ",
            "secretary": "å¥½çš„ï¼Œæˆ‘æ¥å¸®ä½ å¤„ç†è¿™ä¸ªä»»åŠ¡ã€‚\n\n[æ‰§è¡Œä¸­...]\n\nä»»åŠ¡å·²å®Œæˆï¼Œè¿˜æœ‰ä»€ä¹ˆéœ€è¦æˆ‘å¸®å¿™çš„å—ï¼Ÿ",
            "friend": "æˆ‘èƒ½ç†è§£ä½ ç°åœ¨çš„æ„Ÿå—ã€‚\n\nå¦‚æœä½ æ„¿æ„çš„è¯ï¼Œå¯ä»¥å’Œæˆ‘è¯´è¯´å‘ç”Ÿäº†ä»€ä¹ˆï¼Œæˆ‘ä¼šä¸€ç›´åœ¨è¿™é‡Œå¬ä½ è¯´çš„ã€‚"
        }

        return mock_responses.get(role, "æˆ‘éœ€è¦æ›´å¤šä¿¡æ¯æ¥å¸®åŠ©ä½ ã€‚")

    def _log_interaction(self, user_input: str, response: str, role: str):
        """è®°å½•äº¤äº’"""
        # æ·»åŠ åˆ°å½“å‰å¯¹è¯
        self.current_conversation["messages"].append({
            "role": "user",
            "content": user_input
        })
        self.current_conversation["messages"].append({
            "role": "assistant",
            "content": response
        })

        # è®°å½•åˆ°äº¤äº’æ—¥å¿—
        self.memory.log_interaction(
            user_input=user_input,
            agent_response=response,
            role=role,
            metadata={"conversation_id": self.current_conversation["id"]}
        )

    def end_conversation(self):
        """ç»“æŸå¯¹è¯"""
        # ä¿å­˜å®Œæ•´å¯¹è¯
        self.memory.save_conversation(
            self.current_conversation["id"],
            self.current_conversation
        )

        # æ›´æ–°ç»Ÿè®¡
        user_model = self.user_model_manager.get_model()
        user_model["stats"]["total_conversations"] += 1
        self.memory.save_user_model(user_model)

        print(f"\nâœ“ å¯¹è¯å·²ä¿å­˜: {self.current_conversation['id']}")

    def update_user_info(self, key: str, value: Any):
        """æ›´æ–°ç”¨æˆ·ä¿¡æ¯"""
        self.user_model_manager.update_basic_info(key, value)

    def add_goal(self, goal: str, timeframe: str = "short_term"):
        """æ·»åŠ ç›®æ ‡"""
        self.user_model_manager.add_goal(goal, timeframe)

    def backup(self):
        """å¤‡ä»½æ•°æ®"""
        self.memory.backup()


def main():
    """å‘½ä»¤è¡Œæµ‹è¯•å…¥å£"""
    print("=" * 60)
    print("MOSS Assistant - è‹æ ¼æ‹‰åº•å¼è¾©è®ºä¼™ä¼´ + å…¨èƒ½ä¸ªäººåŠ©ç†")
    print("=" * 60)

    # åˆå§‹åŒ–åŠ©æ‰‹
    moss = MOSSAssistant()

    # å¼€å§‹å¯¹è¯
    greeting = moss.start_conversation()
    print("\n" + greeting)

    # äº¤äº’å¾ªç¯
    while True:
        try:
            user_input = input("\nä½ : ").strip()

            if not user_input:
                continue

            if user_input.lower() in ["é€€å‡º", "exit", "quit", "q"]:
                print("\næ­£åœ¨ä¿å­˜å¯¹è¯...")
                moss.end_conversation()
                print("å†è§ï¼ğŸ‘‹")
                break

            # ç‰¹æ®Šå‘½ä»¤
            if user_input.startswith("/info "):
                key, value = user_input[6:].split(" ", 1)
                moss.update_user_info(key, value)
                continue

            if user_input.startswith("/goal "):
                goal = user_input[6:]
                moss.add_goal(goal)
                continue

            if user_input == "/backup":
                moss.backup()
                continue

            # æ­£å¸¸å¯¹è¯
            response = moss.chat(user_input)
            print(f"\nMOSS: {response}")

        except KeyboardInterrupt:
            print("\n\næ­£åœ¨ä¿å­˜å¯¹è¯...")
            moss.end_conversation()
            print("å†è§ï¼ğŸ‘‹")
            break
        except Exception as e:
            print(f"\nâŒ é”™è¯¯: {e}")
            continue


if __name__ == "__main__":
    main()
