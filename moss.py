"""
MOSS Assistant - ä¸»ç¨‹åº
è‹æ ¼æ‹‰åº•å¼è¾©è®ºä¼™ä¼´ + å…¨èƒ½ä¸ªäººåŠ©ç†
"""

import os
import yaml
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional

try:
    import anthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False

try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

from core.memory import PersistentMemory
from core.user_model import UserModelManager
from core.router import RoleRouter
from core.integrations import ExternalAgentManager


class MOSSAssistant:
    """MOSS åŠ©æ‰‹æ ¸å¿ƒç±»"""

    def __init__(self, config_path: str = "config.yaml"):
        # åŠ è½½é…ç½®
        self.config = self._load_config(config_path)

        # åˆå§‹åŒ–ç»„ä»¶
        self.memory = PersistentMemory(self.config)
        self.user_model_manager = UserModelManager(self.memory)
        self.router = RoleRouter(self.config)
        self.external_agents = ExternalAgentManager()  # å¤–éƒ¨æ™ºèƒ½ä½“ç®¡ç†å™¨

        # åˆå§‹åŒ– LLM
        self.llm_client = self._init_llm()

        # å½“å‰ä¼šè¯
        self.current_conversation = {
            "id": self._generate_conversation_id(),
            "timestamp": datetime.now().isoformat(),
            "messages": []
        }

    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        config_file = Path(config_path)
        if not config_file.exists():
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")

        with open(config_file, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)

    def _init_llm(self):
        """åˆå§‹åŒ– LLM å®¢æˆ·ç«¯"""
        provider = self.config["llm"]["provider"]
        api_key = os.getenv(self.config["llm"]["api_key_env"])

        if not api_key:
            print("[è­¦å‘Š]  è­¦å‘Š: æœªè®¾ç½® API Keyï¼Œè¯·è®¾ç½®ç¯å¢ƒå˜é‡")
            print(f"   ç¯å¢ƒå˜é‡å: {self.config['llm']['api_key_env']}")
            return None

        if provider == "claude":
            if not ANTHROPIC_AVAILABLE:
                print("[è­¦å‘Š]  è­¦å‘Š: éœ€è¦å®‰è£… anthropic åº“")
                return None
            return anthropic.Anthropic(api_key=api_key)

        elif provider in ["openai", "deepseek"]:
            if not OPENAI_AVAILABLE:
                print("[è­¦å‘Š]  è­¦å‘Š: éœ€è¦å®‰è£… openai åº“")
                return None

            # DeepSeek ä½¿ç”¨ OpenAI å…¼å®¹çš„ API
            base_url = self.config["llm"].get("base_url")
            if provider == "deepseek":
                base_url = base_url or "https://api.deepseek.com"

            return OpenAI(
                api_key=api_key,
                base_url=base_url
            )

        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ LLM æä¾›å•†: {provider}")

    def _generate_conversation_id(self) -> str:
        """ç”Ÿæˆå¯¹è¯ ID"""
        return f"conv_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

    def start_conversation(self) -> str:
        """å¼€å§‹å¯¹è¯ï¼ˆå†·å¯åŠ¨ï¼‰"""
        # è·å–ç”¨æˆ·æ¨¡å‹æ‘˜è¦
        summary = self.user_model_manager.get_summary()

        # æ·»åŠ åˆ°æ¶ˆæ¯å†å²
        self.current_conversation["messages"].append({
            "role": "assistant",
            "content": summary
        })

        return summary

    def _check_and_call_tools(self, user_input: str) -> str:
        """
        æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·ï¼Œå¹¶æ‰§è¡Œ

        Args:
            user_input: ç”¨æˆ·è¾“å…¥

        Returns:
            å·¥å…·è°ƒç”¨ç»“æœï¼Œå¦‚æœä¸éœ€è¦è°ƒç”¨åˆ™è¿”å› None
        """
        # å®šä¹‰å·¥å…·è°ƒç”¨å…³é”®è¯
        tool_keywords = {
            "scan_workspace": ["æ‰«æå·¥ä½œåŒº", "æ‰«æé¡¹ç›®", "å·¥ä½œåŒºç°çŠ¶", "ç”ŸæˆæŠ¥å‘Š", "å¥åº·æŠ¥å‘Š", "è¯Šæ–­æŠ¥å‘Š"],
            "query_projects": ["é¡¹ç›®åˆ—è¡¨", "æŸ¥çœ‹é¡¹ç›®", "é¡¹ç›®çŠ¶æ€", "æ‰€æœ‰é¡¹ç›®"],
            "get_memory": ["è¯»å–è®°å¿†", "AIè®°å¿†", "æˆ‘çš„æ¡£æ¡ˆ"],
            "get_structure": ["é¡¹ç›®ç»“æ„", "æ–‡ä»¶ç»“æ„", "ç›®å½•ç»“æ„"],
        }

        # æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·
        should_call_tool = False
        tool_type = None

        for tool_name, keywords in tool_keywords.items():
            if any(keyword in user_input for keyword in keywords):
                should_call_tool = True
                tool_type = tool_name
                break

        if should_call_tool:
            try:
                from core.workspace_integration import OfficeWorkspaceIntegration
                import json

                # åˆå§‹åŒ–å·¥ä½œåŒºé›†æˆ
                workspace = OfficeWorkspaceIntegration()

                if not workspace.enabled:
                    return "å·¥ä½œåŒºè·¯å¾„ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®ï¼Œè¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®"

                # æ ¹æ®å·¥å…·ç±»å‹è°ƒç”¨ä¸åŒæ–¹æ³•
                if tool_type == "scan_workspace":
                    # è°ƒç”¨è¶…çº§ç®¡å®¶æ‰«æ
                    result = workspace.get_project_structure()

                    if result.get("success"):
                        source = result.get("source", "æœªçŸ¥")

                        if source == "è¶…çº§ç®¡å®¶" and "data" in result:
                            # è¶…çº§ç®¡å®¶è¿”å›çš„å®Œæ•´æ•°æ®
                            data = result["data"]

                            report_lines = [
                                "=== å·¥ä½œåŒºæ‰«ææŠ¥å‘Šï¼ˆè¶…çº§ç®¡å®¶ï¼‰===",
                                f"ç”Ÿæˆæ—¶é—´: {data.get('timestamp', 'æœªçŸ¥')}",
                                f"å·¥ä½œåŒºè·¯å¾„: {data.get('workspace_path', 'æœªçŸ¥')}",
                                ""
                            ]

                            # MCPæœåŠ¡å™¨
                            if "mcp_servers" in data:
                                mcp = data["mcp_servers"]
                                report_lines.extend([
                                    "ã€MCPæœåŠ¡å™¨ã€‘",
                                    f"çŠ¶æ€: {mcp.get('status', 'æœªçŸ¥')}",
                                    f"æ•°é‡: {mcp.get('count', 0)} ä¸ª"
                                ])
                                for server in mcp.get("servers", []):
                                    report_lines.append(f"  - {server.get('name', 'æœªçŸ¥')}")
                                report_lines.append("")

                            # æ•°æ®æ–°é²œåº¦
                            if "data_freshness" in data:
                                fresh = data["data_freshness"]
                                if fresh.get("index_exists"):
                                    report_lines.extend([
                                        "ã€æ•°æ®çŠ¶æ€ã€‘",
                                        f"æœ€åæ‰«æ: {fresh.get('last_scan', 'æœªçŸ¥')}",
                                        f"æ•°æ®å¹´é¾„: {fresh.get('age_hours', 0)} å°æ—¶",
                                        f"æ–°é²œåº¦: {fresh.get('freshness', 'æœªçŸ¥')}",
                                        f"å»ºè®®: {fresh.get('recommendation', 'æ— ')}",
                                        ""
                                    ])

                            # é¡¹ç›®
                            if "projects" in data:
                                projects = data["projects"]
                                report_lines.extend([
                                    "ã€é¡¹ç›®èµ„äº§ã€‘",
                                    f"æ´»è·ƒé¡¹ç›®: {projects.get('active_count', 0)} ä¸ª"
                                ])

                                for p in projects.get("active", []):
                                    report_lines.append(
                                        f"  - {p.get('name', 'æœªçŸ¥'):30s} | "
                                        f"{p.get('last_modified', 'æœªçŸ¥')} | "
                                        f"{p.get('py_files', 0)}ä¸ªæ–‡ä»¶"
                                    )

                                report_lines.append(
                                    f"å½’æ¡£é¡¹ç›®: {projects.get('archived_count', 0)} ä¸ª"
                                )
                                for p in projects.get("archived", []):
                                    report_lines.append(f"  - {p.get('name', 'æœªçŸ¥')}")
                                report_lines.append("")

                            # å·¥å…·
                            if "tools" in data:
                                tools = data["tools"]
                                if "error" not in tools:
                                    report_lines.extend([
                                        "ã€å·¥å…·è„šæœ¬ã€‘",
                                        f"Pythonå·¥å…·: {tools.get('python_tools_count', 0)} ä¸ª",
                                        f"æ‰¹å¤„ç†è„šæœ¬: {tools.get('batch_scripts_count', 0)} ä¸ª",
                                        ""
                                    ])

                            # ç¬”è®°
                            if "notes" in data:
                                notes = data["notes"]
                                report_lines.extend([
                                    "ã€ç¬”è®°å’Œæ–‡æ¡£ã€‘",
                                    f"åˆ†ç±»æ•°é‡: {notes.get('total_categories', 0)} ä¸ª"
                                ])
                                for cat in notes.get("categories", []):
                                    report_lines.append(
                                        f"  - {cat.get('type', 'æœªçŸ¥')}: "
                                        f"{cat.get('count', 0)}ä¸ªæ–‡ä»¶ "
                                        f"({cat.get('location', 'æœªçŸ¥')})"
                                    )
                                report_lines.append("")

                            return "\n".join(report_lines)

                        else:
                            # é™çº§æ–¹æ¡ˆï¼šä½¿ç”¨ç®€å•æ‰«æ
                            structure = result.get("structure", {})
                            report_lines = [
                                "=== å·¥ä½œåŒºæ‰«æç»“æœ ===",
                                f"æ‰«æè·¯å¾„: {result.get('workspace_path')}",
                                f"æ‰«ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
                                ""
                            ]

                            for dir_name, info in structure.items():
                                report_lines.extend([
                                    f"ğŸ“ {dir_name}",
                                    f"   - æ–‡ä»¶æ•°: {info['file_count']}",
                                    f"   - ç›®å½•æ•°: {info['dir_count']}",
                                    f"   - å¤§å°: {info['size_mb']:.2f} MB",
                                    ""
                                ])

                            return "\n".join(report_lines)
                    else:
                        return f"æ‰«æå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"

                elif tool_type == "query_projects":
                    # æŸ¥è¯¢é¡¹ç›®çŠ¶æ€
                    result = workspace.query_projects()

                    if result.get("success"):
                        return f"ã€é¡¹ç›®æŸ¥è¯¢ç»“æœã€‘\n\n{result.get('output', '')}"
                    else:
                        return f"æŸ¥è¯¢å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"

                elif tool_type == "get_memory":
                    # è¯»å–AIè®°å¿†
                    result = workspace.get_memory_info()

                    if result.get("success"):
                        content = result.get("content", "")
                        # åªè¿”å›å‰1000ä¸ªå­—ç¬¦ï¼Œé¿å…å¤ªé•¿
                        preview = content[:1000]
                        if len(content) > 1000:
                            preview += "\n\n...(å†…å®¹è¿‡é•¿ï¼Œå·²æˆªæ–­)"
                        return f"ã€AIè®°å¿†å†…å®¹ã€‘\n\næ–‡ä»¶è·¯å¾„: {result.get('file_path')}\n\n{preview}"
                    else:
                        return f"è¯»å–å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"

                elif tool_type == "get_structure":
                    # è·å–é¡¹ç›®ç»“æ„
                    result = workspace.get_project_structure()
                    if result.get("success"):
                        return json.dumps(result, indent=2, ensure_ascii=False)
                    else:
                        return f"è·å–ç»“æ„å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"

            except Exception as e:
                import traceback
                return f"å·¥å…·è°ƒç”¨å‡ºé”™: {str(e)}\n\nè¯¦ç»†é”™è¯¯:\n{traceback.format_exc()}"

        return None

    def chat(self, user_input: str) -> str:
        """å¤„ç†ç”¨æˆ·è¾“å…¥"""
        # æ­¥éª¤ 0: æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·
        tool_result = self._check_and_call_tools(user_input)
        if tool_result:
            # å¦‚æœå·¥å…·è°ƒç”¨æˆåŠŸï¼Œå°†å·¥å…·ç»“æœæ³¨å…¥åˆ°å¯¹è¯ä¸­
            enhanced_input = f"{user_input}\n\nã€å·¥å…·è°ƒç”¨ç»“æœã€‘\n{tool_result}"
        else:
            enhanced_input = user_input

        # æ­¥éª¤ 1: è·¯ç”±åˆ°åˆé€‚çš„è§’è‰²
        user_model = self.user_model_manager.get_model()
        routing_result = self.router.route(enhanced_input, user_model)

        role = routing_result["role"]
        role_config = routing_result["role_config"]
        reasoning = routing_result["reasoning"]

        print(f"\n[è§’è‰²è·¯ç”±] {role_config['name']} ({reasoning})")

        # æ­¥éª¤ 2: æ„å»ºå¯¹è¯ä¸Šä¸‹æ–‡
        messages = self._build_messages(enhanced_input, role)

        # æ­¥éª¤ 3: è°ƒç”¨ LLM
        response = self._call_llm(messages, role)

        # æ­¥éª¤ 4: è®°å½•äº¤äº’
        self._log_interaction(user_input, response, role)

        # æ­¥éª¤ 5: æ›´æ–°ç”¨æˆ·æ¨¡å‹
        interaction = {
            "user_input": user_input,
            "agent_response": response,
            "role": role,
            "timestamp": datetime.now().isoformat()
        }
        self.user_model_manager.update_after_interaction(interaction)

        return response

    def _build_messages(self, user_input: str, role: str) -> list:
        """æ„å»ºæ¶ˆæ¯åˆ—è¡¨"""
        # è·å–è§’è‰²çš„ system prompt
        system_prompt = self.router.get_role_prompt(role)

        # è·å–ç”¨æˆ·æ¨¡å‹ä¸Šä¸‹æ–‡
        user_model = self.user_model_manager.get_model()
        user_context = self._build_user_context(user_model)

        # æ„å»ºå®Œæ•´æ¶ˆæ¯
        messages = [
            {
                "role": "user",
                "content": f"""ä½ æ˜¯{role}è§’è‰²ã€‚

{system_prompt}

ç”¨æˆ·ä¿¡æ¯ï¼š
{user_context}

ç”¨æˆ·è¾“å…¥ï¼š
{user_input}

è¯·æ ¹æ®ä½ çš„è§’è‰²å®šä½ï¼Œå›åº”ç”¨æˆ·ã€‚"""
            }
        ]

        return messages

    def _build_user_context(self, user_model: Dict[str, Any]) -> str:
        """æ„å»ºç”¨æˆ·ä¸Šä¸‹æ–‡ï¼ˆç»™ LLMï¼‰"""
        context_parts = []

        # åŸºæœ¬ä¿¡æ¯
        basic_info = user_model.get("basic_info", {})
        if any(basic_info.values()):
            context_parts.append("åŸºæœ¬ä¿¡æ¯:")
            for key, value in basic_info.items():
                if value:
                    context_parts.append(f"  - {key}: {value}")

        # è®¤çŸ¥é£æ ¼
        cognitive = user_model.get("cognitive_style", {})
        if any(cognitive.values()):
            context_parts.append("\nè®¤çŸ¥é£æ ¼:")
            for key, values in cognitive.items():
                if values:
                    context_parts.append(f"  - {key}: {', '.join(values)}")

        # æœ€è¿‘è¯é¢˜
        recent_convs = self.memory.load_conversations(limit=3)
        if recent_convs:
            context_parts.append("\næœ€è¿‘è®¨è®ºçš„è¯é¢˜:")
            for i, conv in enumerate(recent_convs, 1):
                if conv.get("messages"):
                    first_msg = conv["messages"][0].get("content", "")[:100]
                    context_parts.append(f"  {i}. {first_msg}...")

        # å½“å‰ç›®æ ‡
        goals = user_model.get("goals", {})
        if any(goals.values()):
            context_parts.append("\nå½“å‰ç›®æ ‡:")
            for timeframe, goal_list in goals.items():
                if goal_list:
                    context_parts.append(f"  - {timeframe}: {', '.join(goal_list[:2])}")

        return "\n".join(context_parts)

    def _call_llm(self, messages: list, role: str) -> str:
        """è°ƒç”¨ LLM"""
        if not self.llm_client:
            return self._mock_response(role)

        try:
            provider = self.config["llm"]["provider"]
            model = self.config["llm"]["model"]
            max_tokens = self.config["llm"]["max_tokens"]

            if provider == "claude":
                # ä½¿ç”¨ Claude API
                response = self.llm_client.messages.create(
                    model=model,
                    max_tokens=max_tokens,
                    messages=messages
                )
                return response.content[0].text

            elif provider in ["openai", "deepseek"]:
                # ä½¿ç”¨ OpenAI å…¼å®¹ API
                response = self.llm_client.chat.completions.create(
                    model=model,
                    messages=messages,
                    max_tokens=max_tokens
                )
                return response.choices[0].message.content

            else:
                return self._mock_response(role)

        except Exception as e:
            print(f"[è­¦å‘Š]  LLM è°ƒç”¨å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return self._mock_response(role)

    def _mock_response(self, role: str) -> str:
        """æ¨¡æ‹Ÿå“åº”ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
        mock_responses = {
            "mentor": "ä½œä¸ºä½ çš„å¯¼å¸ˆï¼Œæˆ‘æƒ³å…ˆé—®ä½ å‡ ä¸ªé—®é¢˜ï¼š\n\n1. ä½ ä¸ºä»€ä¹ˆè¿™ä¸ªé€‰æ‹©å¯¹ä½ é‡è¦ï¼Ÿ\n2. ä½ æœ‰æ²¡æœ‰è€ƒè™‘è¿‡æœ€åçš„æƒ…å†µï¼Ÿ\n3. å¦‚æœ10å¹´åå›çœ‹è¿™ä¸ªå†³å®šï¼Œä½ ä¼šæœ‰ä»€ä¹ˆæ„Ÿè§‰ï¼Ÿ\n\næˆ‘ä»¬å…ˆæŠŠè¿™äº›æƒ³æ¸…æ¥šï¼Œå†åšå†³å®šã€‚",
            "partner": "è¿™ä¸ªé—®é¢˜å¾ˆæœ‰æ„æ€ï¼è®©æˆ‘ä»¬ä¸€èµ·æ¢ç´¢ä¸€ä¸‹ã€‚\n\næˆ‘æ³¨æ„åˆ°ä½ æåˆ°äº†XXï¼Œè¿™è®©æˆ‘æƒ³åˆ°å¦ä¸€ä¸ªè§’åº¦...ä½ è§‰å¾—å‘¢ï¼Ÿ",
            "secretary": "å¥½çš„ï¼Œæˆ‘æ¥å¸®ä½ å¤„ç†è¿™ä¸ªä»»åŠ¡ã€‚\n\n[æ‰§è¡Œä¸­...]\n\nä»»åŠ¡å·²å®Œæˆï¼Œè¿˜æœ‰ä»€ä¹ˆéœ€è¦æˆ‘å¸®å¿™çš„å—ï¼Ÿ",
            "friend": "æˆ‘èƒ½ç†è§£ä½ ç°åœ¨çš„æ„Ÿå—ã€‚\n\nå¦‚æœä½ æ„¿æ„çš„è¯ï¼Œå¯ä»¥å’Œæˆ‘è¯´è¯´å‘ç”Ÿäº†ä»€ä¹ˆï¼Œæˆ‘ä¼šä¸€ç›´åœ¨è¿™é‡Œå¬ä½ è¯´çš„ã€‚"
        }

        return mock_responses.get(role, "æˆ‘éœ€è¦æ›´å¤šä¿¡æ¯æ¥å¸®åŠ©ä½ ã€‚")

    def _log_interaction(self, user_input: str, response: str, role: str):
        """è®°å½•äº¤äº’"""
        # æ·»åŠ åˆ°å½“å‰å¯¹è¯
        self.current_conversation["messages"].append({
            "role": "user",
            "content": user_input
        })
        self.current_conversation["messages"].append({
            "role": "assistant",
            "content": response
        })

        # è®°å½•åˆ°äº¤äº’æ—¥å¿—
        self.memory.log_interaction(
            user_input=user_input,
            agent_response=response,
            role=role,
            metadata={"conversation_id": self.current_conversation["id"]}
        )

    def end_conversation(self):
        """ç»“æŸå¯¹è¯"""
        # ä¿å­˜å®Œæ•´å¯¹è¯
        self.memory.save_conversation(
            self.current_conversation["id"],
            self.current_conversation
        )

        # æ›´æ–°ç»Ÿè®¡
        user_model = self.user_model_manager.get_model()
        user_model["stats"]["total_conversations"] += 1
        self.memory.save_user_model(user_model)

        print(f"\n[æˆåŠŸ] å¯¹è¯å·²ä¿å­˜: {self.current_conversation['id']}")

    def update_user_info(self, key: str, value: Any):
        """æ›´æ–°ç”¨æˆ·ä¿¡æ¯"""
        self.user_model_manager.update_basic_info(key, value)

    def add_goal(self, goal: str, timeframe: str = "short_term"):
        """æ·»åŠ ç›®æ ‡"""
        self.user_model_manager.add_goal(goal, timeframe)

    def backup(self):
        """å¤‡ä»½æ•°æ®"""
        self.memory.backup()

    def call_external_agent(self, agent_id: str, method: str, *args, **kwargs) -> Dict[str, Any]:
        """
        è°ƒç”¨å¤–éƒ¨æ™ºèƒ½ä½“

        Args:
            agent_id: æ™ºèƒ½ä½“ ID (å¦‚ "workspace_manager")
            method: æ–¹æ³•å
            *args: ä½ç½®å‚æ•°
            **kwargs: å…³é”®å­—å‚æ•°

        Returns:
            æ‰§è¡Œç»“æœ
        """
        return self.external_agents.call_agent(agent_id, method, *args, **kwargs)

    def register_agent(self, agent_id: str, config: Dict[str, Any]):
        """
        æ³¨å†Œæ–°çš„å¤–éƒ¨æ™ºèƒ½ä½“

        Args:
            agent_id: æ™ºèƒ½ä½“ ID
            config: é…ç½®ä¿¡æ¯
        """
        self.external_agents.register_agent(agent_id, config)


def main():
    """å‘½ä»¤è¡Œæµ‹è¯•å…¥å£"""
    print("=" * 60)
    print("MOSS Assistant - è‹æ ¼æ‹‰åº•å¼è¾©è®ºä¼™ä¼´ + å…¨èƒ½ä¸ªäººåŠ©ç†")
    print("=" * 60)

    # åˆå§‹åŒ–åŠ©æ‰‹
    moss = MOSSAssistant()

    # å¼€å§‹å¯¹è¯
    greeting = moss.start_conversation()
    print("\n" + greeting)

    # äº¤äº’å¾ªç¯
    while True:
        try:
            user_input = input("\nä½ : ").strip()

            if not user_input:
                continue

            if user_input.lower() in ["é€€å‡º", "exit", "quit", "q"]:
                print("\næ­£åœ¨ä¿å­˜å¯¹è¯...")
                moss.end_conversation()
                print("å†è§ï¼ğŸ‘‹")
                break

            # ç‰¹æ®Šå‘½ä»¤
            if user_input.startswith("/info "):
                key, value = user_input[6:].split(" ", 1)
                moss.update_user_info(key, value)
                continue

            if user_input.startswith("/goal "):
                goal = user_input[6:]
                moss.add_goal(goal)
                continue

            if user_input == "/backup":
                moss.backup()
                continue

            # æ­£å¸¸å¯¹è¯
            response = moss.chat(user_input)
            print(f"\nMOSS: {response}")

        except KeyboardInterrupt:
            print("\n\næ­£åœ¨ä¿å­˜å¯¹è¯...")
            moss.end_conversation()
            print("å†è§ï¼ğŸ‘‹")
            break
        except Exception as e:
            print(f"\nâŒ é”™è¯¯: {e}")
            continue


if __name__ == "__main__":
    main()
